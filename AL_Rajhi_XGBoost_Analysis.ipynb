{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¦ AL Rajhi Bank Stock Forecasting: XGBoost Analysis with SHAP\n",
        "\n",
        "## Project Walkthrough\n",
        "\n",
        "### Project Summary\n",
        "Built a comprehensive XGBoost-based stock price forecasting model for AL Rajhi Bank (1120.SR) covering all 6 prompts.\n",
        "\n",
        "---\n",
        "\n",
        "### What Was Accomplished\n",
        "| Prompt | Description | Status |\n",
        "|--------|-------------|--------|\n",
        "| 1 | Problem Definition & Model Selection | âœ… |\n",
        "| 2 | Feature Engineering (57 features) | âœ… |\n",
        "| 3 | Modeling Pipeline with GridSearchCV | âœ… |\n",
        "| 4 | Explainability & Business Insights | âœ… |\n",
        "| 5 | Data Storytelling Narrative | âœ… |\n",
        "| 6 | Dashboard Design Concept | âœ… |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3211ed8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(filename = \"AL Rajhi Bank Stock Forecasting XGBoost.png\", width = 500, height = 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML Libraries\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "\n",
        "# SHAP for Explainability\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ SHAP not installed. Run: %pip install shap\")\n",
        "    SHAP_AVAILABLE = False\n",
        "\n",
        "# Plotly for Interactive Visualizations\n",
        "try:\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "    PLOTLY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ Plotly not installed. Run: %pip install plotly\")\n",
        "    PLOTLY_AVAILABLE = False\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‚ Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('AL_Rjehei.csv')\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "print(f\"ğŸ“Š Dataset Shape: {df.shape}\")\n",
        "print(f\"ğŸ“… Date Range: {df['Date'].min()} to {df['Date'].max()}\")\n",
        "print(f\"ğŸ“ˆ Total Trading Days: {len(df)}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Prompt 1: Problem Definition & Model Selection\n",
        "\n",
        "### ğŸ¯ Target Variable & Problem Type\n",
        "- **Target**: `Close` (Closing Price)\n",
        "- **Problem Type**: **Regression + Time-Series Forecasting**\n",
        "\n",
        "### ğŸ“Œ Why XGBoost is Suitable\n",
        "| Reason | Description |\n",
        "|--------|-------------|\n",
        "| Non-linear | Handles complex non-linear relationships |\n",
        "| Feature Interactions | Captures feature interactions automatically |\n",
        "| Missing Values | Built-in handling of missing values |\n",
        "| Regularization | L1/L2 regularization prevents overfitting |\n",
        "| Interpretability | Feature importance for explainability |\n",
        "| Speed | Faster than deep learning models |\n",
        "\n",
        "### âš ï¸ Assumptions & Limitations\n",
        "1. Does NOT natively handle sequential dependencies â†’ Use lag features\n",
        "2. Assumes patterns persist â†’ May fail during regime changes\n",
        "3. Sensitive to hyperparameters â†’ Use GridSearchCV\n",
        "4. Cannot extrapolate beyond training range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Prompt 2: Feature Engineering (XGBoost Optimized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for feature engineering\n",
        "df_ml = df.copy()\n",
        "\n",
        "# 1ï¸âƒ£ DATE-BASED FEATURES\n",
        "print(\"ğŸ“… Creating Date-Based Features...\")\n",
        "df_ml['Year'] = df_ml['Date'].dt.year\n",
        "df_ml['Month'] = df_ml['Date'].dt.month\n",
        "df_ml['Day'] = df_ml['Date'].dt.day\n",
        "df_ml['DayOfWeek'] = df_ml['Date'].dt.dayofweek\n",
        "df_ml['Quarter'] = df_ml['Date'].dt.quarter\n",
        "df_ml['WeekOfYear'] = df_ml['Date'].dt.isocalendar().week.astype(int)\n",
        "df_ml['IsMonthStart'] = df_ml['Date'].dt.is_month_start.astype(int)\n",
        "df_ml['IsMonthEnd'] = df_ml['Date'].dt.is_month_end.astype(int)\n",
        "print(\"  âœ“ Year, Month, Day, DayOfWeek, Quarter, WeekOfYear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2ï¸âƒ£ LAG FEATURES\n",
        "print(\"â³ Creating Lag Features...\")\n",
        "lag_periods = [1, 2, 3, 5, 10, 20]\n",
        "for lag in lag_periods:\n",
        "    df_ml[f'Close_Lag_{lag}'] = df_ml['Close'].shift(lag)\n",
        "    df_ml[f'Volume_Lag_{lag}'] = df_ml['Volume'].shift(lag)\n",
        "print(f\"  âœ“ Lag features for periods: {lag_periods}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3ï¸âƒ£ ROLLING STATISTICS\n",
        "print(\"ğŸ“Š Creating Rolling Statistics...\")\n",
        "windows = [5, 10, 20, 50]\n",
        "for window in windows:\n",
        "    df_ml[f'MA_{window}'] = df_ml['Close'].rolling(window=window).mean()\n",
        "    df_ml[f'Rolling_Std_{window}'] = df_ml['Close'].rolling(window=window).std()\n",
        "    df_ml[f'Rolling_Min_{window}'] = df_ml['Close'].rolling(window=window).min()\n",
        "    df_ml[f'Rolling_Max_{window}'] = df_ml['Close'].rolling(window=window).max()\n",
        "print(f\"  âœ“ Rolling stats for windows: {windows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4ï¸âƒ£ PRICE-DERIVED FEATURES\n",
        "print(\"ğŸ’° Creating Price-Derived Features...\")\n",
        "df_ml['Daily_Return'] = df_ml['Close'].pct_change() * 100\n",
        "df_ml['Price_Range'] = df_ml['High'] - df_ml['Low']\n",
        "df_ml['Price_Range_Pct'] = (df_ml['High'] - df_ml['Low']) / df_ml['Close'] * 100\n",
        "df_ml['Gap'] = df_ml['Open'] - df_ml['Close'].shift(1)\n",
        "df_ml['Gap_Pct'] = df_ml['Gap'] / df_ml['Close'].shift(1) * 100\n",
        "df_ml['High_Low_Ratio'] = df_ml['High'] / df_ml['Low']\n",
        "df_ml['Close_Open_Diff'] = df_ml['Close'] - df_ml['Open']\n",
        "print(\"  âœ“ Daily_Return, Price_Range, Gap, High_Low_Ratio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5ï¸âƒ£ VOLATILITY FEATURES\n",
        "print(\"ğŸ“ˆ Creating Volatility Features...\")\n",
        "df_ml['Volatility_5'] = df_ml['Daily_Return'].rolling(window=5).std()\n",
        "df_ml['Volatility_20'] = df_ml['Daily_Return'].rolling(window=20).std()\n",
        "print(\"  âœ“ 5-day and 20-day volatility\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6ï¸âƒ£ TECHNICAL INDICATORS\n",
        "print(\"ğŸ”§ Creating Technical Indicators...\")\n",
        "\n",
        "# RSI (Relative Strength Index)\n",
        "def calculate_rsi(prices, period=14):\n",
        "    delta = prices.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "df_ml['RSI_14'] = calculate_rsi(df_ml['Close'], 14)\n",
        "\n",
        "# MACD\n",
        "df_ml['EMA_12'] = df_ml['Close'].ewm(span=12, adjust=False).mean()\n",
        "df_ml['EMA_26'] = df_ml['Close'].ewm(span=26, adjust=False).mean()\n",
        "df_ml['MACD'] = df_ml['EMA_12'] - df_ml['EMA_26']\n",
        "df_ml['MACD_Signal'] = df_ml['MACD'].ewm(span=9, adjust=False).mean()\n",
        "df_ml['MACD_Histogram'] = df_ml['MACD'] - df_ml['MACD_Signal']\n",
        "\n",
        "# Bollinger Bands\n",
        "df_ml['BB_Middle'] = df_ml['Close'].rolling(window=20).mean()\n",
        "df_ml['BB_Std'] = df_ml['Close'].rolling(window=20).std()\n",
        "df_ml['BB_Upper'] = df_ml['BB_Middle'] + (df_ml['BB_Std'] * 2)\n",
        "df_ml['BB_Lower'] = df_ml['BB_Middle'] - (df_ml['BB_Std'] * 2)\n",
        "df_ml['BB_Width'] = (df_ml['BB_Upper'] - df_ml['BB_Lower']) / df_ml['BB_Middle']\n",
        "df_ml['BB_Position'] = (df_ml['Close'] - df_ml['BB_Lower']) / (df_ml['BB_Upper'] - df_ml['BB_Lower'])\n",
        "\n",
        "print(\"  âœ“ RSI (14-period)\")\n",
        "print(\"  âœ“ MACD, Signal Line, Histogram\")\n",
        "print(\"  âœ“ Bollinger Bands (Width, Position)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7ï¸âƒ£ HANDLE MISSING VALUES\n",
        "print(\"ğŸ”§ Handling Missing Values...\")\n",
        "initial_rows = len(df_ml)\n",
        "df_ml = df_ml.dropna()\n",
        "final_rows = len(df_ml)\n",
        "print(f\"  âœ“ Dropped {initial_rows - final_rows} rows with NaN values\")\n",
        "print(f\"  âœ“ Remaining samples: {final_rows}\")\n",
        "\n",
        "# Feature Summary\n",
        "feature_cols = [col for col in df_ml.columns if col not in ['Date', 'Close']]\n",
        "print(f\"\\nğŸ“‹ Total Features Created: {len(feature_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Prompt 3: Modeling Pipeline (Professional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare Features and Target\n",
        "feature_columns = [col for col in df_ml.columns if col not in ['Date', 'Close', 'Open', 'High', 'Low', 'Volume']]\n",
        "X = df_ml[feature_columns]\n",
        "y = df_ml['Close']\n",
        "\n",
        "print(f\"ğŸ“Š Feature Matrix Shape: {X.shape}\")\n",
        "print(f\"ğŸ¯ Target Variable: Close Price\")\n",
        "\n",
        "# TIME-AWARE TRAIN/TEST SPLIT\n",
        "print(\"\\nâ±ï¸ Time-Aware Train/Test Split...\")\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "dates_test = df_ml['Date'].iloc[split_idx:]\n",
        "\n",
        "print(f\"  âœ“ Training samples: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"  âœ“ Testing samples: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BASELINE MODEL\n",
        "print(\"ğŸš€ Training Baseline XGBoost Model...\")\n",
        "baseline_model = xgb.XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "baseline_model.fit(X_train, y_train)\n",
        "baseline_pred = baseline_model.predict(X_test)\n",
        "\n",
        "baseline_rmse = np.sqrt(mean_squared_error(y_test, baseline_pred))\n",
        "baseline_mae = mean_absolute_error(y_test, baseline_pred)\n",
        "baseline_r2 = r2_score(y_test, baseline_pred)\n",
        "\n",
        "print(f\"  Baseline RMSE: {baseline_rmse:.4f}\")\n",
        "print(f\"  Baseline MAE: {baseline_mae:.4f}\")\n",
        "print(f\"  Baseline RÂ²: {baseline_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HYPERPARAMETER TUNING\n",
        "print(\"ğŸ”§ Hyperparameter Tuning with GridSearchCV...\")\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    xgb_model,\n",
        "    param_grid,\n",
        "    cv=tscv,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"â³ Running GridSearchCV (this may take a few minutes)...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nâœ… Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"âœ… Best CV Score (RMSE): {-grid_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FINAL MODEL EVALUATION\n",
        "print(\"ğŸ“Š Final Model Evaluation...\")\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"\\n\" + \"â”\"*50)\n",
        "print(\"ğŸ“ˆ FINAL MODEL PERFORMANCE METRICS\")\n",
        "print(\"â”\"*50)\n",
        "print(f\"  RMSE: {rmse:.4f}\")\n",
        "print(f\"  MAE: {mae:.4f}\")\n",
        "print(f\"  RÂ² Score: {r2:.4f}\")\n",
        "print(f\"  MAPE: {mape:.2f}%\")\n",
        "print(\"â”\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FEATURE IMPORTANCE\n",
        "print(\"ğŸ“Š Feature Importance Analysis...\")\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nğŸ” Top 10 Most Important Features:\")\n",
        "feature_importance.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Prompt 4: Explainability & Insights (SHAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if SHAP_AVAILABLE:\n",
        "    print(\"ğŸ” Generating SHAP Values...\")\n",
        "    \n",
        "    # Create SHAP explainer\n",
        "    explainer = shap.TreeExplainer(best_model)\n",
        "    shap_values = explainer.shap_values(X_test)\n",
        "    \n",
        "    # Calculate mean absolute SHAP values\n",
        "    shap_importance = pd.DataFrame({\n",
        "        'Feature': feature_columns,\n",
        "        'SHAP_Importance': np.abs(shap_values).mean(axis=0)\n",
        "    }).sort_values('SHAP_Importance', ascending=False)\n",
        "    \n",
        "    print(\"\\nğŸ” Top 10 Features by SHAP Importance:\")\n",
        "    display(shap_importance.head(10))\n",
        "    \n",
        "    # SHAP Summary Plot\n",
        "    print(\"\\nğŸ“Š Creating SHAP Summary Plot...\")\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=True, max_display=15)\n",
        "    \n",
        "else:\n",
        "    print(\"âš ï¸ SHAP not available. Using XGBoost feature importance.\")\n",
        "    shap_importance = feature_importance.copy()\n",
        "    shap_importance.columns = ['Feature', 'SHAP_Importance']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ’¡ Business Insights\n",
        "\n",
        "**Top Predictive Features:**\n",
        "1. Rolling_Max_10 / Rolling_Max_20 - Price ceiling indicators\n",
        "2. MA_5 - Short-term trend direction\n",
        "3. EMA_12 - Exponential trend signal\n",
        "4. Rolling_Min_10 - Support level indicator\n",
        "\n",
        "**Trading Signals:**\n",
        "- Lag features (previous day prices) are strong predictors\n",
        "- Moving averages indicate trend direction\n",
        "- RSI and MACD provide momentum signals\n",
        "- Volatility features capture market uncertainty\n",
        "\n",
        "**Actionable Recommendations:**\n",
        "- Monitor 5-day and 20-day moving averages for trend changes\n",
        "- RSI above 70 suggests overbought conditions\n",
        "- RSI below 30 suggests oversold conditions\n",
        "- High volatility periods require caution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Prompt 5: Data Storytelling Narrative\n",
        "\n",
        "### ğŸ¦ Business Context\n",
        "AL Rajhi Bank (1120.SR) is one of the largest Islamic banks in the world and a cornerstone of the Saudi Arabian financial sector. Understanding its stock price dynamics is crucial for investors and analysts alike.\n",
        "\n",
        "### ğŸ“Š Key EDA Findings\n",
        "- **Long-term Growth**: Positive trend from 2010-2025 reflecting Saudi economic growth\n",
        "- **Volatility Patterns**: Cyclical patterns correlate with market events\n",
        "- **Trading Volume**: Higher volumes during significant price moves indicate institutional interest\n",
        "\n",
        "### ğŸ¤– Why XGBoost Was Chosen\n",
        "1. Excels at capturing non-linear relationships\n",
        "2. Built-in regularization prevents overfitting\n",
        "3. Feature importance provides interpretable insights\n",
        "4. Faster training than deep learning alternatives\n",
        "\n",
        "### ğŸ’¡ Actionable Recommendations\n",
        "1. **Trend Following**: Use 20-day MA crossovers for entry/exit signals\n",
        "2. **Momentum Trading**: RSI extremes (<30 or >70) suggest reversal opportunities\n",
        "3. **Risk Management**: Reduce position sizes during high volatility periods\n",
        "4. **Retraining**: Update model monthly with new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Prompt 6: Dashboard Design & Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if PLOTLY_AVAILABLE:\n",
        "    print(\"ğŸ“Š Generating Interactive Dashboard Visualizations...\")\n",
        "    \n",
        "    # 1. Predictions vs Actuals\n",
        "    fig1 = go.Figure()\n",
        "    fig1.add_trace(go.Scatter(\n",
        "        x=dates_test, y=y_test,\n",
        "        mode='lines', name='Actual',\n",
        "        line=dict(color='#1f77b4', width=2)\n",
        "    ))\n",
        "    fig1.add_trace(go.Scatter(\n",
        "        x=dates_test, y=y_pred,\n",
        "        mode='lines', name='Predicted',\n",
        "        line=dict(color='#ff7f0e', width=2, dash='dash')\n",
        "    ))\n",
        "    fig1.update_layout(\n",
        "        title='ğŸ“ˆ Predictions vs Actuals',\n",
        "        xaxis_title='Date',\n",
        "        yaxis_title='Close Price (SAR)',\n",
        "        hovermode='x unified',\n",
        "        template='plotly_white',\n",
        "        height=500\n",
        "    )\n",
        "    fig1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if PLOTLY_AVAILABLE:\n",
        "    # 2. Feature Importance Chart\n",
        "    top_n = 15\n",
        "    fig2 = px.bar(\n",
        "        feature_importance.head(top_n),\n",
        "        x='Importance', y='Feature',\n",
        "        orientation='h',\n",
        "        title='ğŸ“Š Top 15 Feature Importance (XGBoost)',\n",
        "        color='Importance',\n",
        "        color_continuous_scale='Blues'\n",
        "    )\n",
        "    fig2.update_layout(\n",
        "        yaxis={'categoryorder': 'total ascending'},\n",
        "        template='plotly_white',\n",
        "        height=500\n",
        "    )\n",
        "    fig2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matplotlib visualization as backup\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(dates_test.values, y_test.values, label='Actual', color='#1f77b4', linewidth=2)\n",
        "plt.plot(dates_test.values, y_pred, label='Predicted', color='#ff7f0e', linestyle='--', linewidth=2)\n",
        "plt.title('Predictions vs Actuals', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price (SAR)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‹ Project Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"ğŸ“‹ PROJECT SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\"\"\n",
        "ğŸ¦ PROJECT: AL Rajhi Bank Stock Forecasting\n",
        "ğŸ“Š MODEL: XGBoost Regressor with SHAP Explainability\n",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "\n",
        "âœ… COMPLETED TASKS:\n",
        "  1. Problem Definition: Regression + Forecasting on Close price\n",
        "  2. Feature Engineering: {len(feature_columns)} features created\n",
        "  3. Modeling Pipeline: TimeSeriesSplit CV with GridSearchCV tuning\n",
        "  4. Explainability: Feature importance analysis\n",
        "  5. Storytelling: Professional business narrative\n",
        "  6. Dashboard: Interactive visualizations\n",
        "\n",
        "ğŸ“ˆ FINAL MODEL PERFORMANCE:\n",
        "  â€¢ RÂ² Score: {r2:.4f}\n",
        "  â€¢ RMSE: {rmse:.4f}\n",
        "  â€¢ MAE: {mae:.4f}\n",
        "  â€¢ MAPE: {mape:.2f}%\n",
        "\n",
        "ğŸ·ï¸ KAGGLE PROJECT NAME:\n",
        "  \"AL Rajhi Bank Stock Forecasting: XGBoost Analysis with SHAP\"\n",
        "\n",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nâœ… Analysis Complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python_ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
